{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import walk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP = {\n",
    "    'epochs': 25,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 1e-3,\n",
    "    'momentum': 0.9,\n",
    "    'test_size': 0.05,\n",
    "    'seed': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu device\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(HP['seed'])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if device == 'cuda':\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "print(f'using {device} device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 10407 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>variety</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8845</th>\n",
       "      <td>107872.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8148</th>\n",
       "      <td>105537.jpg</td>\n",
       "      <td>normal</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701</th>\n",
       "      <td>105132.jpg</td>\n",
       "      <td>downy_mildew</td>\n",
       "      <td>AtchayaPonni</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9601</th>\n",
       "      <td>105680.jpg</td>\n",
       "      <td>tungro</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>102240.jpg</td>\n",
       "      <td>brown_spot</td>\n",
       "      <td>ADT45</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_id         label       variety  age\n",
       "8845  107872.jpg        normal         ADT45   70\n",
       "8148  105537.jpg        normal         ADT45   60\n",
       "5701  105132.jpg  downy_mildew  AtchayaPonni   45\n",
       "9601  105680.jpg        tungro         ADT45   60\n",
       "3649  102240.jpg    brown_spot         ADT45   72"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = 'data/train_images/'\n",
    "submission_dir = 'data/test_images/'\n",
    "dataset_file = 'data/train.csv'\n",
    "submission_sample = 'data/sample_submission.csv'\n",
    "\n",
    "df = pd.read_csv(dataset_file)\n",
    "df = shuffle(df, random_state=HP['seed'])\n",
    "\n",
    "print(f'count: {len(df)} \\n')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>1.440761</td>\n",
       "      <td>2.421698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>10407.0</td>\n",
       "      <td>64.043624</td>\n",
       "      <td>8.958830</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count       mean       std   min   25%   50%   75%   max\n",
       "variety  10407.0   1.440761  2.421698   0.0   0.0   0.0   2.0   9.0\n",
       "age      10407.0  64.043624  8.958830  45.0  60.0  67.0  70.0  82.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['variety'] = pd.factorize(df['variety'])[0]\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'normal': 0, 'downy_mildew': 1, 'tungro': 2, 'brown_spot': 3, 'blast': 4, 'bacterial_leaf_streak': 5, 'bacterial_leaf_blight': 6, 'hispa': 7, 'dead_heart': 8, 'bacterial_panicle_blight': 9}\n"
     ]
    }
   ],
   "source": [
    "idx_to_label = df['label'].unique()\n",
    "label_to_idx = {idx: label for label, idx in enumerate(idx_to_label)}\n",
    "print(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 9886, test len: 521\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=HP['test_size'])\n",
    "print(f'train len: {len(train_df)}, test len: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal                      1658\n",
       "blast                       1650\n",
       "hispa                       1514\n",
       "dead_heart                  1371\n",
       "tungro                      1030\n",
       "brown_spot                   916\n",
       "downy_mildew                 600\n",
       "bacterial_leaf_blight        455\n",
       "bacterial_leaf_streak        364\n",
       "bacterial_panicle_blight     328\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.Pad(padding=10),\n",
    "        transforms.CenterCrop(480),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.CenterCrop((576,432)),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.1,\n",
    "            contrast=0.1, \n",
    "            saturation=0.1,\n",
    "            hue=0.1\n",
    "        )\n",
    "    ]),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "class PaddyDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, df, label_to_idx, transforms):\n",
    "        self.df = df\n",
    "        self.label_to_idx = label_to_idx\n",
    "        self.transforms = transforms\n",
    "        self.df['path'] = dataset_dir + '/' + self.df.label + '/' + self.df.image_id\n",
    "        # 0: image_id, 1: label, 2: variety, 3: age, 4: path\n",
    "        self.df = self.df.values.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df[idx]\n",
    "        image = Image.open(row[4])\n",
    "        image = self.transforms(image)\n",
    "        idx = self.label_to_idx[row[1]]\n",
    "        return image, idx\n",
    "\n",
    "\n",
    "train_dataset = PaddyDataset(dataset_dir, train_df, label_to_idx, train_transform)\n",
    "test_dataset = PaddyDataset(dataset_dir, test_df, label_to_idx, test_transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=HP['batch_size'], shuffle=True, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=HP['batch_size'], shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jh931201/opt/anaconda3/envs/boost/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/jh931201/opt/anaconda3/envs/boost/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /Users/jh931201/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b065236cc1dd4e95b71140785de38426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = models.resnet34(pretrained=True)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Linear(model.fc.in_features, len(label_to_idx))\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=HP['learning_rate'], momentum=HP['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, test_dataloader):\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_test_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    with tqdm(train_dataloader, unit='batch', leave=False) as pbar:\n",
    "        pbar.set_description(f'training')\n",
    "        for images, idxs in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            idxs = idxs.to(device, non_blocking=True)\n",
    "            output = model(images)\n",
    "\n",
    "            loss = criterion(output, idxs)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    model.eval()\n",
    "    with tqdm(test_dataloader, unit='batch', leave=False) as pbar:\n",
    "        pbar.set_description(f'testing')\n",
    "        for images, idxs in pbar:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            idxs = idxs.to(device, non_blocking=True)\n",
    "\n",
    "            output = model(images)\n",
    "            loss = criterion(output, idxs)\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "    train_acc = total_train_loss / len(train_dataset)\n",
    "    test_acc = total_test_loss / len(test_dataset)\n",
    "    print(f'Train loss: {train_acc:.4f} Test loss: {test_acc:.4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[1;32m/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb 셀 12\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb#ch0000013?line=13'>14</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, idxs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb#ch0000013?line=14'>15</a>\u001b[0m total_train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb#ch0000013?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb#ch0000013?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jh931201/AI6-likelion/kaggle/paddy-disease-classification/paddy-disease.ipynb#ch0000013?line=18'>19</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/boost/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/boost/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(HP['epochs']):\n",
    "    print(f\"Epoch {i+1}/{HP['epochs']}\")\n",
    "    train(model, criterion, optimizer, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.eval()\n",
    "image_ids, labels = [], []\n",
    "for (dirpath, dirname, filenames) in walk(submission_dir):\n",
    "    for filename in filenames:\n",
    "        image = Image.open(dirpath+filename)\n",
    "        image = test_transform(image)\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        image_ids.append(filename)\n",
    "        labels.append(idx_to_label[model(image).argmax().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'image_id': image_ids,\n",
    "    'label': labels,\n",
    "})\n",
    "# submission['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission.to_csv(submission_output, index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('boost')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2d8127a3b7fe563b278cfab245d7f5be4982e827e9750b085e647417aee25d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
